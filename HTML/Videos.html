<!DOCTYPE html>
<html>
<head>
<style>
    body{
        background-color: #e6fff9;
        padding:30px;
    }
video{
    float:left;
    padding:10px;
}
h2{
color:rgb(3, 108, 139);
}


</style>
</head>
<body>
<h1>Srinivasa Doveloper Directory</h1>
 <h2>
     Who are we ?
 </h2>
 <p>

    Inferencing, on the other hand, is the process of using a trained model to produce a probable match for a new piece of data relative to all the data that the model was trained on. Inferencing, in most applications, looks for quick answers that can be arrived at in milliseconds. Examples of inferencing include speech recognition, real-time language translation, machine vision, and ad insertion optimization decisions. When compared to training, inferencing requires a small fraction of the processing power. However, this is still well beyond the processing provided by traditional CPU-based systems. Thus, even with inferencing, acceleration (either on the SoC as IP or as an in-system accelerator) is required to achieve reasonable execution speeds.
 </p>
 <h2>
    What Skills Do Our Dovelopers Have?
</h2>
<p>
    Inferencing, on the other hand, is the process of using a trained model to produce a probable match for a new piece of data relative to all the data that the model was trained on. Inferencing, in most applications, looks for quick answers that can be arrived at in milliseconds. Examples of inferencing include speech recognition, real-time language translation, machine vision, and ad insertion optimization decisions. When compared to training, inferencing requires a small fraction of the processing power. However, this is still well beyond the processing provided by traditional CPU-based systems. Thus, even with inferencing, acceleration (either on the SoC as IP or as an in-system accelerator) is required to achieve reasonable execution speeds.
</p>
<p>
 
    <video target="aa" width="60%" controls poster="D:\INFO\imges\shutterstock_285147194.jpg">
        <source src="D:\movies\songs\Ghatikudu_-_Asale_Pilla_Video__Suriya__Nayanthara__Harris_Jayaraj(1080p).mp4" type="video/mp4"/>
       
</video>
<p>
    Inferencing, on the other hand, is the process of using a trained model to produce a probable match for a new piece of data relative to all the data that the model was trained on. Inferencing, in most applications, looks for quick answers that can be arrived at in milliseconds. Examples of inferencing include speech recognition, real-time language translation, machine vision, and ad insertion optimization decisions. When compared to training, inferencing requires a small fraction of the processing power. However, this is still well beyond the processing provided by traditional CPU-based systems. Thus, even with inferencing, acceleration (either on the SoC as IP or as an in-system accelerator) is required to achieve reasonable execution speeds.
</p>
<p>
    Inferencing, on the other hand, is the process of using a trained model to produce a probable match for a new piece of data relative to all the data that the model was trained on. Inferencing, in most applications, looks for quick answers that can be arrived at in milliseconds. Examples of inferencing include speech recognition, real-time language translation, machine vision, and ad insertion optimization decisions. When compared to training, inferencing requires a small fraction of the processing power. However, this is still well beyond the processing provided by traditional CPU-based systems. Thus, even with inferencing, acceleration (either on the SoC as IP or as an in-system accelerator) is required to achieve reasonable execution speeds.
</p>
</p>



</body>
</html>

